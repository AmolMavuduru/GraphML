{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from karateclub import GraphReader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import pyprind\n",
    "from pyprind import ProgBar\n",
    "import random as pyrandom\n",
    "pyrandom.seed(1)\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = GraphReader(\"facebook\")\n",
    "\n",
    "graph = reader.get_graph()\n",
    "target = reader.get_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22470"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepWalk Graph Embedding and ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from karateclub import DeepWalk\n",
    "deepwalk = DeepWalk(walk_length=100, dimensions=256)\n",
    "deepwalk.fit(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = deepwalk.get_embedding()\n",
    "y = target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75      1340\n",
      "           1       0.65      0.52      0.58       671\n",
      "           2       0.70      0.71      0.71      1125\n",
      "           3       0.77      0.78      0.78      1358\n",
      "\n",
      "    accuracy                           0.72      4494\n",
      "   macro avg       0.71      0.70      0.70      4494\n",
      "weighted avg       0.72      0.72      0.72      4494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.4f}'.format(acc))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6302\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.67      1340\n",
      "           1       0.89      0.13      0.22       671\n",
      "           2       0.66      0.54      0.59      1125\n",
      "           3       0.62      0.83      0.71      1358\n",
      "\n",
      "    accuracy                           0.63      4494\n",
      "   macro avg       0.70      0.56      0.55      4494\n",
      "weighted avg       0.67      0.63      0.60      4494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.4f}'.format(acc))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 100, 100), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "neural_net = MLPClassifier(hidden_layer_sizes=(100, 100, 100))\n",
    "neural_net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1340\n",
      "           1       0.71      0.71      0.71       671\n",
      "           2       0.83      0.81      0.82      1125\n",
      "           3       0.82      0.84      0.83      1358\n",
      "\n",
      "    accuracy                           0.81      4494\n",
      "   macro avg       0.79      0.79      0.79      4494\n",
      "weighted avg       0.81      0.81      0.81      4494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = neural_net.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.4f}'.format(acc))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Deeper Neural Network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    verbose=2,\n",
    "    mode=\"min\")\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    verbose=2,\n",
    "    mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 230us/step - loss: 1.1348 - accuracy: 0.5797 - val_loss: 0.9645 - val_accuracy: 0.7061\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 174us/step - loss: 0.8835 - accuracy: 0.7190 - val_loss: 0.8018 - val_accuracy: 0.7468\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 176us/step - loss: 0.7276 - accuracy: 0.7714 - val_loss: 0.7146 - val_accuracy: 0.7597\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 179us/step - loss: 0.6162 - accuracy: 0.8055 - val_loss: 0.6779 - val_accuracy: 0.7615\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 180us/step - loss: 0.5328 - accuracy: 0.8348 - val_loss: 0.6298 - val_accuracy: 0.7848\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 182us/step - loss: 0.4646 - accuracy: 0.8590 - val_loss: 0.6131 - val_accuracy: 0.7897\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 182us/step - loss: 0.4071 - accuracy: 0.8784 - val_loss: 0.6065 - val_accuracy: 0.7946\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 185us/step - loss: 0.3592 - accuracy: 0.8951 - val_loss: 0.6072 - val_accuracy: 0.8026\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 190us/step - loss: 0.3236 - accuracy: 0.9088 - val_loss: 0.5956 - val_accuracy: 0.8093\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 3s 188us/step - loss: 0.2919 - accuracy: 0.9187 - val_loss: 0.6134 - val_accuracy: 0.8024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ffc45f869d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "\n",
    "model.fit(X_train, y_train_cat, \n",
    "          validation_data=(X_test, y_test_cat),\n",
    "          batch_size=32, epochs=10,\n",
    "         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4494/4494 [==============================] - 0s 51us/step\n",
      "Accuracy: 0.8024\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(X_test, y_test_cat)\n",
    "print('Accuracy: {:.4f}'.format(evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walklets Embedding and ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from karateclub import Walklets\n",
    "walklet_embedder = Walklets(dimensions=128)\n",
    "walklet_embedder.fit(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = walklet_embedder.get_embedding()\n",
    "y = target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amol/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      1340\n",
      "           1       0.89      0.85      0.87       671\n",
      "           2       0.94      0.94      0.94      1125\n",
      "           3       0.92      0.93      0.92      1358\n",
      "\n",
      "    accuracy                           0.92      4494\n",
      "   macro avg       0.91      0.91      0.91      4494\n",
      "weighted avg       0.92      0.92      0.92      4494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.4f}'.format(acc))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 100, 100), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "neural_net = MLPClassifier(hidden_layer_sizes=(100, 100, 100))\n",
    "neural_net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9310\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93      1340\n",
      "           1       0.93      0.86      0.89       671\n",
      "           2       0.96      0.94      0.95      1125\n",
      "           3       0.94      0.94      0.94      1358\n",
      "\n",
      "    accuracy                           0.93      4494\n",
      "   macro avg       0.93      0.92      0.93      4494\n",
      "weighted avg       0.93      0.93      0.93      4494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = neural_net.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.4f}'.format(acc))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    verbose=2,\n",
    "    mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 240us/step - loss: 0.3757 - accuracy: 0.8748 - val_loss: 0.2926 - val_accuracy: 0.9092\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 190us/step - loss: 0.2689 - accuracy: 0.9105 - val_loss: 0.2766 - val_accuracy: 0.9097\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 192us/step - loss: 0.2331 - accuracy: 0.9211 - val_loss: 0.2616 - val_accuracy: 0.9146\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 192us/step - loss: 0.2123 - accuracy: 0.9300 - val_loss: 0.2381 - val_accuracy: 0.9221\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 194us/step - loss: 0.1932 - accuracy: 0.9364 - val_loss: 0.2345 - val_accuracy: 0.9255\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 193us/step - loss: 0.1850 - accuracy: 0.9375 - val_loss: 0.2342 - val_accuracy: 0.9275\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 194us/step - loss: 0.1783 - accuracy: 0.9375 - val_loss: 0.2160 - val_accuracy: 0.9346\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 193us/step - loss: 0.1602 - accuracy: 0.9439 - val_loss: 0.2459 - val_accuracy: 0.9268\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 193us/step - loss: 0.1521 - accuracy: 0.9472 - val_loss: 0.2269 - val_accuracy: 0.9324\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ffc0f000d50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "\n",
    "model.fit(X_train, y_train_cat, \n",
    "          validation_data=(X_test, y_test_cat),\n",
    "          batch_size=32, epochs=10,\n",
    "         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4494/4494 [==============================] - 0s 48us/step\n",
      "Accuracy: 0.9324\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(X_test, y_test_cat)\n",
    "print('Accuracy: {:.4f}'.format(evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model) == keras.engine.sequential.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cat.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_keras_neural_net(embedding_dimensions, n_classes):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(embedding_dimensions))\n",
    "    model.add(Dense(embedding_dimensions, activation='relu'))\n",
    "    model.add(Dense(embedding_dimensions, activation='relu'))\n",
    "    model.add(Dense(embedding_dimensions, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_graph_model(ml_model, walk_length, embedding_dimensions, graph, target):\n",
    "    \n",
    "    embedding_model = Walklets(walk_length = walk_length, dimensions = embedding_dimensions)\n",
    "    embedding_model.fit(graph)\n",
    "    X = embedding_model.get_embedding()\n",
    "    y = target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    if ml_model == 'neural network':\n",
    "        \n",
    "        y_train_cat = to_categorical(y_train)\n",
    "        y_test_cat = to_categorical(y_test)\n",
    "        n_classes = y_test_cat.shape[1]\n",
    "        ml_model = build_keras_neural_net(embedding_dimensions, n_classes)\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor=\"val_loss\", patience=2, verbose=2, mode=\"min\")\n",
    "        \n",
    "        ml_model.fit(X_train, y_train_cat, \n",
    "          validation_data=(X_test, y_test_cat),\n",
    "          batch_size=32, epochs=10,\n",
    "         callbacks=[early_stopping])\n",
    "        \n",
    "        score = ml_model.evaluate(X_test, y_test_cat)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        ml_model.fit(X_train, y_train)\n",
    "        y_pred = neural_net.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        return acc\n",
    "\n",
    "def grid_search(ml_model, param_grid, graph, target):\n",
    "    \n",
    "    walk_lengths = param_grid['walk_length']\n",
    "    embedding_dimension_vals = param_grid['embedding_dimensions']\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    n = len(walk_lengths) * len(embedding_dimension_vals)\n",
    "    pbar = ProgBar(n, track_time=True, monitor=True)\n",
    "    \n",
    "    for walk_length in walk_lengths:\n",
    "        for embedding_dimensions in embedding_dimension_vals:\n",
    "            score = evaluate_graph_model(ml_model, walk_length, embedding_dimensions, graph, target)\n",
    "            data_dict = {'walk_length': walk_length, \n",
    "                         'embedding_dimensions': embedding_dimensions, \n",
    "                         'accuracy': score[1]}\n",
    "            \n",
    "            rows.append(data_dict)\n",
    "            pbar.update()\n",
    "            \n",
    "    print(pbar)\n",
    "    return pd.DataFrame(rows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 3s 180us/step - loss: 0.4272 - accuracy: 0.8587 - val_loss: 0.3085 - val_accuracy: 0.8972\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 2s 134us/step - loss: 0.3040 - accuracy: 0.8975 - val_loss: 0.3044 - val_accuracy: 0.9012\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 2s 138us/step - loss: 0.2684 - accuracy: 0.9102 - val_loss: 0.2649 - val_accuracy: 0.9083\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 2s 139us/step - loss: 0.2454 - accuracy: 0.9155 - val_loss: 0.2805 - val_accuracy: 0.9023\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 142us/step - loss: 0.2301 - accuracy: 0.9215 - val_loss: 0.2544 - val_accuracy: 0.9139\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 142us/step - loss: 0.2121 - accuracy: 0.9281 - val_loss: 0.2434 - val_accuracy: 0.9215\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 142us/step - loss: 0.2055 - accuracy: 0.9303 - val_loss: 0.2457 - val_accuracy: 0.9188\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 144us/step - loss: 0.1933 - accuracy: 0.9332 - val_loss: 0.2596 - val_accuracy: 0.9161\n",
      "Epoch 00008: early stopping\n",
      "4494/4494 [==============================] - 0s 46us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 198us/step - loss: 0.4290 - accuracy: 0.8578 - val_loss: 0.3181 - val_accuracy: 0.8959\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 152us/step - loss: 0.3010 - accuracy: 0.8988 - val_loss: 0.3042 - val_accuracy: 0.9023\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 154us/step - loss: 0.2679 - accuracy: 0.9095 - val_loss: 0.2718 - val_accuracy: 0.9059\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 156us/step - loss: 0.2486 - accuracy: 0.9147 - val_loss: 0.2918 - val_accuracy: 0.8999\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 158us/step - loss: 0.2268 - accuracy: 0.9213 - val_loss: 0.2578 - val_accuracy: 0.9121\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 159us/step - loss: 0.2124 - accuracy: 0.9260 - val_loss: 0.2751 - val_accuracy: 0.9090\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 159us/step - loss: 0.2031 - accuracy: 0.9276 - val_loss: 0.2448 - val_accuracy: 0.9190\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 160us/step - loss: 0.1916 - accuracy: 0.9341 - val_loss: 0.2362 - val_accuracy: 0.9217\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 160us/step - loss: 0.1806 - accuracy: 0.9373 - val_loss: 0.2495 - val_accuracy: 0.9208\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 3s 160us/step - loss: 0.1771 - accuracy: 0.9381 - val_loss: 0.2570 - val_accuracy: 0.9190\n",
      "Epoch 00010: early stopping\n",
      "4494/4494 [==============================] - 0s 45us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [#                             ] 100% | ETA: 01:45:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 207us/step - loss: 0.4265 - accuracy: 0.8583 - val_loss: 0.3135 - val_accuracy: 0.8934\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 158us/step - loss: 0.2996 - accuracy: 0.8985 - val_loss: 0.3037 - val_accuracy: 0.9043\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 160us/step - loss: 0.2673 - accuracy: 0.9093 - val_loss: 0.2657 - val_accuracy: 0.9101\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 164us/step - loss: 0.2445 - accuracy: 0.9182 - val_loss: 0.2768 - val_accuracy: 0.9041\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 164us/step - loss: 0.2270 - accuracy: 0.9227 - val_loss: 0.2601 - val_accuracy: 0.9121\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 168us/step - loss: 0.2125 - accuracy: 0.9265 - val_loss: 0.2712 - val_accuracy: 0.9085\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 167us/step - loss: 0.2011 - accuracy: 0.9300 - val_loss: 0.2416 - val_accuracy: 0.9181\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 166us/step - loss: 0.1907 - accuracy: 0.9334 - val_loss: 0.2500 - val_accuracy: 0.9210\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 168us/step - loss: 0.1845 - accuracy: 0.9356 - val_loss: 0.2387 - val_accuracy: 0.9243\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 3s 168us/step - loss: 0.1741 - accuracy: 0.9384 - val_loss: 0.2494 - val_accuracy: 0.9228\n",
      "4494/4494 [==============================] - 0s 46us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [##                            ] 100% | ETA: 01:44:15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 221us/step - loss: 0.4231 - accuracy: 0.8603 - val_loss: 0.3264 - val_accuracy: 0.8872\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 174us/step - loss: 0.3029 - accuracy: 0.8982 - val_loss: 0.2994 - val_accuracy: 0.9083\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 181us/step - loss: 0.2697 - accuracy: 0.9094 - val_loss: 0.2661 - val_accuracy: 0.9110\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 181us/step - loss: 0.2462 - accuracy: 0.9168 - val_loss: 0.3245 - val_accuracy: 0.8832\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 184us/step - loss: 0.2289 - accuracy: 0.9217 - val_loss: 0.2499 - val_accuracy: 0.9159\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 186us/step - loss: 0.2156 - accuracy: 0.9250 - val_loss: 0.2777 - val_accuracy: 0.9068\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 186us/step - loss: 0.2093 - accuracy: 0.9278 - val_loss: 0.2335 - val_accuracy: 0.9208\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 187us/step - loss: 0.1937 - accuracy: 0.9327 - val_loss: 0.2441 - val_accuracy: 0.9208\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 187us/step - loss: 0.1853 - accuracy: 0.9349 - val_loss: 0.2322 - val_accuracy: 0.9263\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 3s 186us/step - loss: 0.1755 - accuracy: 0.9388 - val_loss: 0.2443 - val_accuracy: 0.9221\n",
      "4494/4494 [==============================] - 0s 44us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 282us/step - loss: 0.4251 - accuracy: 0.8576 - val_loss: 0.3179 - val_accuracy: 0.8923\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 200us/step - loss: 0.3009 - accuracy: 0.8991 - val_loss: 0.3095 - val_accuracy: 0.8990\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 203us/step - loss: 0.2668 - accuracy: 0.9111 - val_loss: 0.2781 - val_accuracy: 0.9005\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 207us/step - loss: 0.2429 - accuracy: 0.9189 - val_loss: 0.2989 - val_accuracy: 0.8979\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 217us/step - loss: 0.2268 - accuracy: 0.9218 - val_loss: 0.2542 - val_accuracy: 0.9134\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 211us/step - loss: 0.2118 - accuracy: 0.9266 - val_loss: 0.2536 - val_accuracy: 0.9190\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 212us/step - loss: 0.2053 - accuracy: 0.9296 - val_loss: 0.2407 - val_accuracy: 0.9239\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 4s 213us/step - loss: 0.1933 - accuracy: 0.9337 - val_loss: 0.2595 - val_accuracy: 0.9159\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 4s 218us/step - loss: 0.1833 - accuracy: 0.9350 - val_loss: 0.2529 - val_accuracy: 0.9239\n",
      "Epoch 00009: early stopping\n",
      "4494/4494 [==============================] - 0s 51us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [###                           ] 100% | ETA: 01:45:47"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 281us/step - loss: 0.4222 - accuracy: 0.8596 - val_loss: 0.3287 - val_accuracy: 0.8923\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 205us/step - loss: 0.2983 - accuracy: 0.8997 - val_loss: 0.3179 - val_accuracy: 0.8941\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 211us/step - loss: 0.2708 - accuracy: 0.9080 - val_loss: 0.2769 - val_accuracy: 0.9077\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 213us/step - loss: 0.2442 - accuracy: 0.9159 - val_loss: 0.2801 - val_accuracy: 0.9050\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 212us/step - loss: 0.2288 - accuracy: 0.9211 - val_loss: 0.2403 - val_accuracy: 0.9226\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 216us/step - loss: 0.2155 - accuracy: 0.9253 - val_loss: 0.2638 - val_accuracy: 0.9161\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 215us/step - loss: 0.2068 - accuracy: 0.9290 - val_loss: 0.2379 - val_accuracy: 0.9263\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 4s 217us/step - loss: 0.1942 - accuracy: 0.9330 - val_loss: 0.2265 - val_accuracy: 0.9281\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 4s 215us/step - loss: 0.1838 - accuracy: 0.9345 - val_loss: 0.2442 - val_accuracy: 0.9223\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 4s 216us/step - loss: 0.1776 - accuracy: 0.9374 - val_loss: 0.2509 - val_accuracy: 0.9217\n",
      "Epoch 00010: early stopping\n",
      "4494/4494 [==============================] - 0s 51us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 293us/step - loss: 0.4219 - accuracy: 0.8624 - val_loss: 0.3378 - val_accuracy: 0.8858\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 217us/step - loss: 0.3022 - accuracy: 0.8973 - val_loss: 0.3079 - val_accuracy: 0.9014\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 222us/step - loss: 0.2705 - accuracy: 0.9090 - val_loss: 0.2801 - val_accuracy: 0.9034\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 224us/step - loss: 0.2460 - accuracy: 0.9161 - val_loss: 0.3126 - val_accuracy: 0.8981\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 225us/step - loss: 0.2349 - accuracy: 0.9185 - val_loss: 0.2412 - val_accuracy: 0.9194\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 227us/step - loss: 0.2156 - accuracy: 0.9246 - val_loss: 0.2589 - val_accuracy: 0.9141\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 227us/step - loss: 0.2086 - accuracy: 0.9277 - val_loss: 0.2441 - val_accuracy: 0.9201\n",
      "Epoch 00007: early stopping\n",
      "4494/4494 [==============================] - 0s 51us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [####                          ] 100% | ETA: 01:48:26"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 6s 310us/step - loss: 0.4208 - accuracy: 0.8609 - val_loss: 0.3591 - val_accuracy: 0.8769\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 237us/step - loss: 0.3049 - accuracy: 0.8966 - val_loss: 0.3091 - val_accuracy: 0.8994\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 5s 271us/step - loss: 0.2734 - accuracy: 0.9090 - val_loss: 0.2730 - val_accuracy: 0.9081\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 5s 251us/step - loss: 0.2465 - accuracy: 0.9176 - val_loss: 0.2948 - val_accuracy: 0.8947\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 249us/step - loss: 0.2273 - accuracy: 0.9215 - val_loss: 0.2508 - val_accuracy: 0.9168\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 5s 253us/step - loss: 0.2154 - accuracy: 0.9255 - val_loss: 0.2708 - val_accuracy: 0.9072\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 5s 255us/step - loss: 0.2106 - accuracy: 0.9268 - val_loss: 0.2379 - val_accuracy: 0.9237\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 5s 257us/step - loss: 0.1970 - accuracy: 0.9312 - val_loss: 0.2442 - val_accuracy: 0.9217\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 5s 252us/step - loss: 0.1861 - accuracy: 0.9342 - val_loss: 0.2360 - val_accuracy: 0.9237\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 5s 251us/step - loss: 0.1843 - accuracy: 0.9352 - val_loss: 0.2340 - val_accuracy: 0.9215\n",
      "4494/4494 [==============================] - 0s 54us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [#####                         ] 100% | ETA: 01:48:57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 6s 311us/step - loss: 0.4265 - accuracy: 0.8581 - val_loss: 0.3346 - val_accuracy: 0.8923\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 233us/step - loss: 0.3033 - accuracy: 0.8983 - val_loss: 0.3077 - val_accuracy: 0.8983\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 239us/step - loss: 0.2731 - accuracy: 0.9091 - val_loss: 0.2738 - val_accuracy: 0.9085\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 242us/step - loss: 0.2453 - accuracy: 0.9194 - val_loss: 0.3186 - val_accuracy: 0.8899\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 245us/step - loss: 0.2332 - accuracy: 0.9196 - val_loss: 0.2366 - val_accuracy: 0.9199\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 246us/step - loss: 0.2157 - accuracy: 0.9256 - val_loss: 0.2811 - val_accuracy: 0.9088\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 247us/step - loss: 0.2110 - accuracy: 0.9281 - val_loss: 0.2392 - val_accuracy: 0.9215\n",
      "Epoch 00007: early stopping\n",
      "4494/4494 [==============================] - 0s 53us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [######                        ] 100% | ETA: 01:47:50"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 231us/step - loss: 0.4292 - accuracy: 0.8559 - val_loss: 0.3056 - val_accuracy: 0.9023\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 152us/step - loss: 0.2938 - accuracy: 0.9019 - val_loss: 0.2900 - val_accuracy: 0.9057\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 152us/step - loss: 0.2571 - accuracy: 0.9143 - val_loss: 0.2511 - val_accuracy: 0.9188\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 154us/step - loss: 0.2394 - accuracy: 0.9187 - val_loss: 0.2709 - val_accuracy: 0.9072\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 156us/step - loss: 0.2173 - accuracy: 0.9252 - val_loss: 0.2365 - val_accuracy: 0.9210\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 157us/step - loss: 0.2037 - accuracy: 0.9311 - val_loss: 0.2399 - val_accuracy: 0.9248\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 158us/step - loss: 0.1938 - accuracy: 0.9335 - val_loss: 0.2312 - val_accuracy: 0.9257\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 159us/step - loss: 0.1833 - accuracy: 0.9366 - val_loss: 0.2261 - val_accuracy: 0.9266\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 159us/step - loss: 0.1774 - accuracy: 0.9389 - val_loss: 0.2304 - val_accuracy: 0.9270\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 3s 159us/step - loss: 0.1652 - accuracy: 0.9421 - val_loss: 0.2486 - val_accuracy: 0.9190\n",
      "Epoch 00010: early stopping\n",
      "4494/4494 [==============================] - 0s 47us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 240us/step - loss: 0.4164 - accuracy: 0.8620 - val_loss: 0.3045 - val_accuracy: 0.9021\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 162us/step - loss: 0.2951 - accuracy: 0.9011 - val_loss: 0.2843 - val_accuracy: 0.9072\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 163us/step - loss: 0.2597 - accuracy: 0.9154 - val_loss: 0.2518 - val_accuracy: 0.9183\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 163us/step - loss: 0.2356 - accuracy: 0.9190 - val_loss: 0.2691 - val_accuracy: 0.9085\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 166us/step - loss: 0.2195 - accuracy: 0.9243 - val_loss: 0.2488 - val_accuracy: 0.9168\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 167us/step - loss: 0.2057 - accuracy: 0.9298 - val_loss: 0.2638 - val_accuracy: 0.9143\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 168us/step - loss: 0.1962 - accuracy: 0.9330 - val_loss: 0.2280 - val_accuracy: 0.9241\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 167us/step - loss: 0.1834 - accuracy: 0.9365 - val_loss: 0.2302 - val_accuracy: 0.9295\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 168us/step - loss: 0.1771 - accuracy: 0.9389 - val_loss: 0.2251 - val_accuracy: 0.9275\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 3s 169us/step - loss: 0.1692 - accuracy: 0.9388 - val_loss: 0.2498 - val_accuracy: 0.9235\n",
      "4494/4494 [==============================] - 0s 49us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [#######                       ] 100% | ETA: 01:47:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 248us/step - loss: 0.4110 - accuracy: 0.8644 - val_loss: 0.2966 - val_accuracy: 0.9048\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 168us/step - loss: 0.2885 - accuracy: 0.9028 - val_loss: 0.2751 - val_accuracy: 0.9083\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 172us/step - loss: 0.2536 - accuracy: 0.9169 - val_loss: 0.2556 - val_accuracy: 0.9159\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 177us/step - loss: 0.2346 - accuracy: 0.9202 - val_loss: 0.2782 - val_accuracy: 0.9068\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 179us/step - loss: 0.2168 - accuracy: 0.9242 - val_loss: 0.2381 - val_accuracy: 0.9203\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 177us/step - loss: 0.2003 - accuracy: 0.9299 - val_loss: 0.2387 - val_accuracy: 0.9270\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 180us/step - loss: 0.1928 - accuracy: 0.9319 - val_loss: 0.2357 - val_accuracy: 0.9243\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 180us/step - loss: 0.1826 - accuracy: 0.9370 - val_loss: 0.2342 - val_accuracy: 0.9230\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 181us/step - loss: 0.1728 - accuracy: 0.9386 - val_loss: 0.2240 - val_accuracy: 0.9299\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 3s 180us/step - loss: 0.1636 - accuracy: 0.9423 - val_loss: 0.2381 - val_accuracy: 0.9272\n",
      "4494/4494 [==============================] - 0s 48us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [########                      ] 100% | ETA: 01:45:59"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 268us/step - loss: 0.4063 - accuracy: 0.8645 - val_loss: 0.2970 - val_accuracy: 0.9023\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 188us/step - loss: 0.2891 - accuracy: 0.9034 - val_loss: 0.2814 - val_accuracy: 0.9074\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 193us/step - loss: 0.2545 - accuracy: 0.9156 - val_loss: 0.2415 - val_accuracy: 0.9194\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 196us/step - loss: 0.2318 - accuracy: 0.9213 - val_loss: 0.2639 - val_accuracy: 0.9132\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 200us/step - loss: 0.2116 - accuracy: 0.9256 - val_loss: 0.2389 - val_accuracy: 0.9208\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 201us/step - loss: 0.2008 - accuracy: 0.9309 - val_loss: 0.2454 - val_accuracy: 0.9243\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 199us/step - loss: 0.1937 - accuracy: 0.9326 - val_loss: 0.2236 - val_accuracy: 0.9235\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 4s 202us/step - loss: 0.1799 - accuracy: 0.9369 - val_loss: 0.2241 - val_accuracy: 0.9257\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 4s 200us/step - loss: 0.1725 - accuracy: 0.9390 - val_loss: 0.2278 - val_accuracy: 0.9279\n",
      "Epoch 00009: early stopping\n",
      "4494/4494 [==============================] - 0s 51us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 259us/step - loss: 0.4000 - accuracy: 0.8648 - val_loss: 0.2975 - val_accuracy: 0.9057\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 226us/step - loss: 0.2859 - accuracy: 0.9030 - val_loss: 0.2894 - val_accuracy: 0.9003\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 217us/step - loss: 0.2480 - accuracy: 0.9158 - val_loss: 0.2466 - val_accuracy: 0.9181\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 210us/step - loss: 0.2296 - accuracy: 0.9212 - val_loss: 0.2563 - val_accuracy: 0.9150\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 209us/step - loss: 0.2122 - accuracy: 0.9254 - val_loss: 0.2324 - val_accuracy: 0.9228\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 216us/step - loss: 0.1993 - accuracy: 0.9299 - val_loss: 0.2468 - val_accuracy: 0.9232\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 222us/step - loss: 0.1900 - accuracy: 0.9351 - val_loss: 0.2216 - val_accuracy: 0.9252\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 4s 207us/step - loss: 0.1797 - accuracy: 0.9383 - val_loss: 0.2285 - val_accuracy: 0.9283\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 4s 222us/step - loss: 0.1710 - accuracy: 0.9419 - val_loss: 0.2236 - val_accuracy: 0.9283\n",
      "Epoch 00009: early stopping\n",
      "4494/4494 [==============================] - 0s 64us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [#########                     ] 100% | ETA: 01:41:55"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 250us/step - loss: 0.4023 - accuracy: 0.8632 - val_loss: 0.2995 - val_accuracy: 0.9077\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 201us/step - loss: 0.2887 - accuracy: 0.9041 - val_loss: 0.2829 - val_accuracy: 0.9068\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 232us/step - loss: 0.2529 - accuracy: 0.9163 - val_loss: 0.2564 - val_accuracy: 0.9119\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 199us/step - loss: 0.2344 - accuracy: 0.9199 - val_loss: 0.2737 - val_accuracy: 0.9132\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 202us/step - loss: 0.2142 - accuracy: 0.9258 - val_loss: 0.2334 - val_accuracy: 0.9215\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 211us/step - loss: 0.1995 - accuracy: 0.9303 - val_loss: 0.2633 - val_accuracy: 0.9203\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 214us/step - loss: 0.1921 - accuracy: 0.9329 - val_loss: 0.2379 - val_accuracy: 0.9230\n",
      "Epoch 00007: early stopping\n",
      "4494/4494 [==============================] - 0s 61us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 6s 331us/step - loss: 0.3976 - accuracy: 0.8669 - val_loss: 0.3151 - val_accuracy: 0.8945\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 243us/step - loss: 0.2889 - accuracy: 0.9013 - val_loss: 0.2945 - val_accuracy: 0.9052\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 217us/step - loss: 0.2569 - accuracy: 0.9144 - val_loss: 0.2534 - val_accuracy: 0.9163\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 218us/step - loss: 0.2312 - accuracy: 0.9210 - val_loss: 0.2690 - val_accuracy: 0.9123\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 218us/step - loss: 0.2158 - accuracy: 0.9257 - val_loss: 0.2415 - val_accuracy: 0.9170\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 221us/step - loss: 0.2065 - accuracy: 0.9255 - val_loss: 0.2456 - val_accuracy: 0.9197\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 216us/step - loss: 0.1979 - accuracy: 0.9320 - val_loss: 0.2219 - val_accuracy: 0.9263\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 4s 221us/step - loss: 0.1839 - accuracy: 0.9352 - val_loss: 0.2259 - val_accuracy: 0.9281\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 4s 221us/step - loss: 0.1756 - accuracy: 0.9378 - val_loss: 0.2337 - val_accuracy: 0.9272\n",
      "Epoch 00009: early stopping\n",
      "4494/4494 [==============================] - 0s 46us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [##########                    ] 100% | ETA: 01:36:27"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 6s 326us/step - loss: 0.3973 - accuracy: 0.8678 - val_loss: 0.3311 - val_accuracy: 0.8883\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 5s 304us/step - loss: 0.2891 - accuracy: 0.9019 - val_loss: 0.2855 - val_accuracy: 0.9025\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 6s 320us/step - loss: 0.2533 - accuracy: 0.9173 - val_loss: 0.2523 - val_accuracy: 0.9174\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 5s 254us/step - loss: 0.2371 - accuracy: 0.9187 - val_loss: 0.2707 - val_accuracy: 0.9070\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 233us/step - loss: 0.2174 - accuracy: 0.9227 - val_loss: 0.2357 - val_accuracy: 0.9199\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 226us/step - loss: 0.2029 - accuracy: 0.9281 - val_loss: 0.2542 - val_accuracy: 0.9192\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 5s 296us/step - loss: 0.1943 - accuracy: 0.9321 - val_loss: 0.2175 - val_accuracy: 0.9290\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 5s 290us/step - loss: 0.1841 - accuracy: 0.9357 - val_loss: 0.2493 - val_accuracy: 0.9186\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 5s 289us/step - loss: 0.1761 - accuracy: 0.9369 - val_loss: 0.2234 - val_accuracy: 0.9317\n",
      "Epoch 00009: early stopping\n",
      "4494/4494 [==============================] - 0s 77us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [###########                   ] 100% | ETA: 01:33:21"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 255us/step - loss: 0.3976 - accuracy: 0.8691 - val_loss: 0.3081 - val_accuracy: 0.9039\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 248us/step - loss: 0.2916 - accuracy: 0.9024 - val_loss: 0.2918 - val_accuracy: 0.9048\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 6s 311us/step - loss: 0.2558 - accuracy: 0.9160 - val_loss: 0.2564 - val_accuracy: 0.9146\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 5s 297us/step - loss: 0.2370 - accuracy: 0.9191 - val_loss: 0.2835 - val_accuracy: 0.9039\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 5s 261us/step - loss: 0.2174 - accuracy: 0.9244 - val_loss: 0.2376 - val_accuracy: 0.9212\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 5s 273us/step - loss: 0.2006 - accuracy: 0.9291 - val_loss: 0.2475 - val_accuracy: 0.9243\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 6s 318us/step - loss: 0.1974 - accuracy: 0.9326 - val_loss: 0.2293 - val_accuracy: 0.9252\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 5s 275us/step - loss: 0.1834 - accuracy: 0.9357 - val_loss: 0.2244 - val_accuracy: 0.9272\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 5s 299us/step - loss: 0.1748 - accuracy: 0.9394 - val_loss: 0.2358 - val_accuracy: 0.9292\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 6s 311us/step - loss: 0.1680 - accuracy: 0.9410 - val_loss: 0.2376 - val_accuracy: 0.9257\n",
      "Epoch 00010: early stopping\n",
      "4494/4494 [==============================] - 0s 55us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [############                  ] 100% | ETA: 01:30:45"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 222us/step - loss: 0.4059 - accuracy: 0.8647 - val_loss: 0.2918 - val_accuracy: 0.9061\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 148us/step - loss: 0.2788 - accuracy: 0.9081 - val_loss: 0.3021 - val_accuracy: 0.8992\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 152us/step - loss: 0.2482 - accuracy: 0.9177 - val_loss: 0.2460 - val_accuracy: 0.9186\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 141us/step - loss: 0.2283 - accuracy: 0.9237 - val_loss: 0.2476 - val_accuracy: 0.9212\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 175us/step - loss: 0.2083 - accuracy: 0.9300 - val_loss: 0.2422 - val_accuracy: 0.9219\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 172us/step - loss: 0.1944 - accuracy: 0.9351 - val_loss: 0.2331 - val_accuracy: 0.9288\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 176us/step - loss: 0.1860 - accuracy: 0.9373 - val_loss: 0.2231 - val_accuracy: 0.9272\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 160us/step - loss: 0.1741 - accuracy: 0.9423 - val_loss: 0.2264 - val_accuracy: 0.9263\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 162us/step - loss: 0.1651 - accuracy: 0.9445 - val_loss: 0.2379 - val_accuracy: 0.9226\n",
      "Epoch 00009: early stopping\n",
      "4494/4494 [==============================] - 0s 40us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 6s 320us/step - loss: 0.4015 - accuracy: 0.8672 - val_loss: 0.2947 - val_accuracy: 0.9094\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 191us/step - loss: 0.2806 - accuracy: 0.9074 - val_loss: 0.2765 - val_accuracy: 0.9083\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 205us/step - loss: 0.2466 - accuracy: 0.9184 - val_loss: 0.2514 - val_accuracy: 0.9192\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 209us/step - loss: 0.2284 - accuracy: 0.9221 - val_loss: 0.2542 - val_accuracy: 0.9174\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 180us/step - loss: 0.2116 - accuracy: 0.9277 - val_loss: 0.2513 - val_accuracy: 0.9194\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 225us/step - loss: 0.1960 - accuracy: 0.9327 - val_loss: 0.2506 - val_accuracy: 0.9215\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 222us/step - loss: 0.1870 - accuracy: 0.9360 - val_loss: 0.2280 - val_accuracy: 0.9299\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 193us/step - loss: 0.1746 - accuracy: 0.9388 - val_loss: 0.2250 - val_accuracy: 0.9297\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 193us/step - loss: 0.1653 - accuracy: 0.9411 - val_loss: 0.2192 - val_accuracy: 0.9341\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 4s 198us/step - loss: 0.1603 - accuracy: 0.9438 - val_loss: 0.2375 - val_accuracy: 0.9288\n",
      "4494/4494 [==============================] - 0s 48us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [#############                 ] 100% | ETA: 01:26:14"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 256us/step - loss: 0.4019 - accuracy: 0.8682 - val_loss: 0.3065 - val_accuracy: 0.8979\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 176us/step - loss: 0.2826 - accuracy: 0.9049 - val_loss: 0.3050 - val_accuracy: 0.9012\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 187us/step - loss: 0.2463 - accuracy: 0.9211 - val_loss: 0.2473 - val_accuracy: 0.9186\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 176us/step - loss: 0.2283 - accuracy: 0.9234 - val_loss: 0.2630 - val_accuracy: 0.9099\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 171us/step - loss: 0.2124 - accuracy: 0.9275 - val_loss: 0.2409 - val_accuracy: 0.9217\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 168us/step - loss: 0.1949 - accuracy: 0.9347 - val_loss: 0.2466 - val_accuracy: 0.9226\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 176us/step - loss: 0.1911 - accuracy: 0.9329 - val_loss: 0.2354 - val_accuracy: 0.9239\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 167us/step - loss: 0.1738 - accuracy: 0.9399 - val_loss: 0.2379 - val_accuracy: 0.9241\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 168us/step - loss: 0.1654 - accuracy: 0.9431 - val_loss: 0.2219 - val_accuracy: 0.9299\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 3s 176us/step - loss: 0.1584 - accuracy: 0.9443 - val_loss: 0.2420 - val_accuracy: 0.9239\n",
      "4494/4494 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [##############                ] 100% | ETA: 01:23:11"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 253us/step - loss: 0.3885 - accuracy: 0.8709 - val_loss: 0.3018 - val_accuracy: 0.8992\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 182us/step - loss: 0.2785 - accuracy: 0.9078 - val_loss: 0.2845 - val_accuracy: 0.9065\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 5s 285us/step - loss: 0.2414 - accuracy: 0.9205 - val_loss: 0.2420 - val_accuracy: 0.9217\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 214us/step - loss: 0.2252 - accuracy: 0.9236 - val_loss: 0.2773 - val_accuracy: 0.9105\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 205us/step - loss: 0.2087 - accuracy: 0.9278 - val_loss: 0.2428 - val_accuracy: 0.9186\n",
      "Epoch 00005: early stopping\n",
      "4494/4494 [==============================] - 0s 49us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 276us/step - loss: 0.3989 - accuracy: 0.8688 - val_loss: 0.3059 - val_accuracy: 0.8996\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 5s 258us/step - loss: 0.2841 - accuracy: 0.9053 - val_loss: 0.2754 - val_accuracy: 0.9121\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 243us/step - loss: 0.2453 - accuracy: 0.9186 - val_loss: 0.2480 - val_accuracy: 0.9203\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 5s 260us/step - loss: 0.2268 - accuracy: 0.9222 - val_loss: 0.2645 - val_accuracy: 0.9150\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 233us/step - loss: 0.2110 - accuracy: 0.9275 - val_loss: 0.2396 - val_accuracy: 0.9252\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 238us/step - loss: 0.1934 - accuracy: 0.9330 - val_loss: 0.2657 - val_accuracy: 0.9177\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 227us/step - loss: 0.1850 - accuracy: 0.9353 - val_loss: 0.2375 - val_accuracy: 0.9210\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 4s 212us/step - loss: 0.1721 - accuracy: 0.9387 - val_loss: 0.2215 - val_accuracy: 0.9315\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 4s 210us/step - loss: 0.1607 - accuracy: 0.9439 - val_loss: 0.2376 - val_accuracy: 0.9270\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 4s 203us/step - loss: 0.1569 - accuracy: 0.9449 - val_loss: 0.2518 - val_accuracy: 0.9241\n",
      "Epoch 00010: early stopping\n",
      "4494/4494 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [###############               ] 100% | ETA: 01:17:18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 244us/step - loss: 0.3899 - accuracy: 0.8734 - val_loss: 0.3086 - val_accuracy: 0.9001\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 192us/step - loss: 0.2806 - accuracy: 0.9059 - val_loss: 0.2876 - val_accuracy: 0.9072\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 209us/step - loss: 0.2450 - accuracy: 0.9194 - val_loss: 0.2638 - val_accuracy: 0.9121\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 230us/step - loss: 0.2248 - accuracy: 0.9241 - val_loss: 0.2605 - val_accuracy: 0.9152\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 193us/step - loss: 0.2073 - accuracy: 0.9283 - val_loss: 0.2351 - val_accuracy: 0.9259\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 191us/step - loss: 0.1932 - accuracy: 0.9335 - val_loss: 0.2536 - val_accuracy: 0.9183\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 213us/step - loss: 0.1860 - accuracy: 0.9346 - val_loss: 0.2166 - val_accuracy: 0.9295\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 4s 205us/step - loss: 0.1679 - accuracy: 0.9416 - val_loss: 0.2187 - val_accuracy: 0.9297\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 4s 212us/step - loss: 0.1630 - accuracy: 0.9423 - val_loss: 0.2307 - val_accuracy: 0.9263\n",
      "Epoch 00009: early stopping\n",
      "4494/4494 [==============================] - 0s 54us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 305us/step - loss: 0.3911 - accuracy: 0.8693 - val_loss: 0.3128 - val_accuracy: 0.8939\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 218us/step - loss: 0.2761 - accuracy: 0.9079 - val_loss: 0.2745 - val_accuracy: 0.9121\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 217us/step - loss: 0.2421 - accuracy: 0.9212 - val_loss: 0.2428 - val_accuracy: 0.9212\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 222us/step - loss: 0.2252 - accuracy: 0.9241 - val_loss: 0.2557 - val_accuracy: 0.9161\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 233us/step - loss: 0.2077 - accuracy: 0.9292 - val_loss: 0.2409 - val_accuracy: 0.9259\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 234us/step - loss: 0.1916 - accuracy: 0.9340 - val_loss: 0.2439 - val_accuracy: 0.9230\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 231us/step - loss: 0.1844 - accuracy: 0.9367 - val_loss: 0.2365 - val_accuracy: 0.9235\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 4s 229us/step - loss: 0.1760 - accuracy: 0.9398 - val_loss: 0.2253 - val_accuracy: 0.9281\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 4s 228us/step - loss: 0.1629 - accuracy: 0.9427 - val_loss: 0.2137 - val_accuracy: 0.9364\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 4s 223us/step - loss: 0.1566 - accuracy: 0.9446 - val_loss: 0.2406 - val_accuracy: 0.9279\n",
      "4494/4494 [==============================] - 0s 54us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [################              ] 100% | ETA: 01:11:29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 297us/step - loss: 0.3838 - accuracy: 0.8733 - val_loss: 0.3110 - val_accuracy: 0.8992\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 245us/step - loss: 0.2790 - accuracy: 0.9064 - val_loss: 0.2824 - val_accuracy: 0.9123\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 238us/step - loss: 0.2432 - accuracy: 0.9203 - val_loss: 0.2399 - val_accuracy: 0.9172\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 234us/step - loss: 0.2255 - accuracy: 0.9222 - val_loss: 0.2657 - val_accuracy: 0.9179\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 232us/step - loss: 0.2086 - accuracy: 0.9283 - val_loss: 0.2410 - val_accuracy: 0.9232\n",
      "Epoch 00005: early stopping\n",
      "4494/4494 [==============================] - 0s 46us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [#################             ] 100% | ETA: 01:08:14"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 275us/step - loss: 0.3921 - accuracy: 0.8695 - val_loss: 0.3159 - val_accuracy: 0.8945\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 215us/step - loss: 0.2865 - accuracy: 0.9048 - val_loss: 0.2893 - val_accuracy: 0.9057\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 215us/step - loss: 0.2475 - accuracy: 0.9177 - val_loss: 0.2536 - val_accuracy: 0.9157\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 218us/step - loss: 0.2283 - accuracy: 0.9232 - val_loss: 0.2642 - val_accuracy: 0.9154\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 234us/step - loss: 0.2121 - accuracy: 0.9265 - val_loss: 0.2491 - val_accuracy: 0.9166\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 234us/step - loss: 0.2002 - accuracy: 0.9307 - val_loss: 0.2640 - val_accuracy: 0.9221\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 239us/step - loss: 0.1893 - accuracy: 0.9340 - val_loss: 0.2456 - val_accuracy: 0.9179\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 4s 224us/step - loss: 0.1774 - accuracy: 0.9384 - val_loss: 0.2405 - val_accuracy: 0.9239\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 4s 218us/step - loss: 0.1692 - accuracy: 0.9404 - val_loss: 0.2339 - val_accuracy: 0.9290\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 4s 216us/step - loss: 0.1613 - accuracy: 0.9445 - val_loss: 0.2520 - val_accuracy: 0.9228\n",
      "4494/4494 [==============================] - 0s 44us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [##################            ] 100% | ETA: 01:04:57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 3s 176us/step - loss: 0.3887 - accuracy: 0.8688 - val_loss: 0.2833 - val_accuracy: 0.9108\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 2s 128us/step - loss: 0.2740 - accuracy: 0.9097 - val_loss: 0.2637 - val_accuracy: 0.9188\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 2s 131us/step - loss: 0.2392 - accuracy: 0.9230 - val_loss: 0.2493 - val_accuracy: 0.9239\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 2s 132us/step - loss: 0.2202 - accuracy: 0.9273 - val_loss: 0.2583 - val_accuracy: 0.9161\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 2s 133us/step - loss: 0.2026 - accuracy: 0.9314 - val_loss: 0.2235 - val_accuracy: 0.9272\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 2s 133us/step - loss: 0.1899 - accuracy: 0.9351 - val_loss: 0.2334 - val_accuracy: 0.9301\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 2s 136us/step - loss: 0.1784 - accuracy: 0.9393 - val_loss: 0.2250 - val_accuracy: 0.9268\n",
      "Epoch 00007: early stopping\n",
      "4494/4494 [==============================] - 0s 41us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 201us/step - loss: 0.3966 - accuracy: 0.8662 - val_loss: 0.2853 - val_accuracy: 0.9103\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 143us/step - loss: 0.2765 - accuracy: 0.9064 - val_loss: 0.2668 - val_accuracy: 0.9197\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 144us/step - loss: 0.2402 - accuracy: 0.9208 - val_loss: 0.2542 - val_accuracy: 0.9159\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 145us/step - loss: 0.2221 - accuracy: 0.9238 - val_loss: 0.2590 - val_accuracy: 0.9152\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 146us/step - loss: 0.2029 - accuracy: 0.9313 - val_loss: 0.2389 - val_accuracy: 0.9241\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 147us/step - loss: 0.1886 - accuracy: 0.9357 - val_loss: 0.2349 - val_accuracy: 0.9270\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 146us/step - loss: 0.1810 - accuracy: 0.9388 - val_loss: 0.2514 - val_accuracy: 0.9188\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 147us/step - loss: 0.1683 - accuracy: 0.9403 - val_loss: 0.2332 - val_accuracy: 0.9246\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 147us/step - loss: 0.1599 - accuracy: 0.9454 - val_loss: 0.2301 - val_accuracy: 0.9335\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 3s 149us/step - loss: 0.1513 - accuracy: 0.9474 - val_loss: 0.2524 - val_accuracy: 0.9279\n",
      "4494/4494 [==============================] - 0s 39us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [###################           ] 100% | ETA: 00:57:52"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 204us/step - loss: 0.3876 - accuracy: 0.8707 - val_loss: 0.2860 - val_accuracy: 0.9063\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 160us/step - loss: 0.2747 - accuracy: 0.9089 - val_loss: 0.2865 - val_accuracy: 0.9079\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 161us/step - loss: 0.2387 - accuracy: 0.9220 - val_loss: 0.2645 - val_accuracy: 0.9139\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 162us/step - loss: 0.2215 - accuracy: 0.9259 - val_loss: 0.2569 - val_accuracy: 0.9186\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 164us/step - loss: 0.2007 - accuracy: 0.9317 - val_loss: 0.2450 - val_accuracy: 0.9252\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 165us/step - loss: 0.1879 - accuracy: 0.9344 - val_loss: 0.2479 - val_accuracy: 0.9221\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 165us/step - loss: 0.1805 - accuracy: 0.9381 - val_loss: 0.2360 - val_accuracy: 0.9219\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 165us/step - loss: 0.1667 - accuracy: 0.9421 - val_loss: 0.2288 - val_accuracy: 0.9304\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 165us/step - loss: 0.1557 - accuracy: 0.9473 - val_loss: 0.2267 - val_accuracy: 0.9319\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 3s 164us/step - loss: 0.1504 - accuracy: 0.9475 - val_loss: 0.2543 - val_accuracy: 0.9230\n",
      "4494/4494 [==============================] - 0s 40us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [####################          ] 100% | ETA: 00:54:24"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 213us/step - loss: 0.3891 - accuracy: 0.8693 - val_loss: 0.3130 - val_accuracy: 0.8985\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 165us/step - loss: 0.2750 - accuracy: 0.9071 - val_loss: 0.2660 - val_accuracy: 0.9139\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 169us/step - loss: 0.2360 - accuracy: 0.9232 - val_loss: 0.2471 - val_accuracy: 0.9192\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 169us/step - loss: 0.2205 - accuracy: 0.9240 - val_loss: 0.2433 - val_accuracy: 0.9194\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 171us/step - loss: 0.2013 - accuracy: 0.9305 - val_loss: 0.2249 - val_accuracy: 0.9319\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 173us/step - loss: 0.1868 - accuracy: 0.9353 - val_loss: 0.2218 - val_accuracy: 0.9310\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 172us/step - loss: 0.1764 - accuracy: 0.9397 - val_loss: 0.2267 - val_accuracy: 0.9259\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 172us/step - loss: 0.1671 - accuracy: 0.9434 - val_loss: 0.2268 - val_accuracy: 0.9299\n",
      "Epoch 00008: early stopping\n",
      "4494/4494 [==============================] - 0s 42us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 224us/step - loss: 0.3789 - accuracy: 0.8740 - val_loss: 0.2899 - val_accuracy: 0.9052\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 180us/step - loss: 0.2694 - accuracy: 0.9105 - val_loss: 0.2681 - val_accuracy: 0.9119\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 183us/step - loss: 0.2371 - accuracy: 0.9227 - val_loss: 0.2465 - val_accuracy: 0.9188\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 183us/step - loss: 0.2189 - accuracy: 0.9247 - val_loss: 0.2565 - val_accuracy: 0.9159\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 187us/step - loss: 0.2015 - accuracy: 0.9317 - val_loss: 0.2242 - val_accuracy: 0.9301\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 188us/step - loss: 0.1843 - accuracy: 0.9377 - val_loss: 0.2371 - val_accuracy: 0.9281\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 187us/step - loss: 0.1830 - accuracy: 0.9364 - val_loss: 0.2342 - val_accuracy: 0.9259\n",
      "Epoch 00007: early stopping\n",
      "4494/4494 [==============================] - 0s 40us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [#####################         ] 100% | ETA: 00:47:19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 6s 306us/step - loss: 0.3813 - accuracy: 0.8712 - val_loss: 0.3014 - val_accuracy: 0.9001\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 5s 269us/step - loss: 0.2745 - accuracy: 0.9082 - val_loss: 0.2860 - val_accuracy: 0.9081\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 5s 260us/step - loss: 0.2405 - accuracy: 0.9212 - val_loss: 0.2544 - val_accuracy: 0.9141\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 5s 260us/step - loss: 0.2206 - accuracy: 0.9254 - val_loss: 0.2759 - val_accuracy: 0.9108\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 6s 322us/step - loss: 0.2023 - accuracy: 0.9309 - val_loss: 0.2199 - val_accuracy: 0.9272\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 5s 288us/step - loss: 0.1877 - accuracy: 0.9364 - val_loss: 0.2371 - val_accuracy: 0.9261\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 211us/step - loss: 0.1788 - accuracy: 0.9386 - val_loss: 0.2288 - val_accuracy: 0.9277\n",
      "Epoch 00007: early stopping\n",
      "4494/4494 [==============================] - 0s 49us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 277us/step - loss: 0.3799 - accuracy: 0.8730 - val_loss: 0.3116 - val_accuracy: 0.9010\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 236us/step - loss: 0.2773 - accuracy: 0.9080 - val_loss: 0.2900 - val_accuracy: 0.9048\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 5s 287us/step - loss: 0.2446 - accuracy: 0.9189 - val_loss: 0.2422 - val_accuracy: 0.9183\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 5s 257us/step - loss: 0.2232 - accuracy: 0.9252 - val_loss: 0.2898 - val_accuracy: 0.9041\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 5s 263us/step - loss: 0.2040 - accuracy: 0.9301 - val_loss: 0.2300 - val_accuracy: 0.9283\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 5s 261us/step - loss: 0.1898 - accuracy: 0.9350 - val_loss: 0.2446 - val_accuracy: 0.9243\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 5s 255us/step - loss: 0.1806 - accuracy: 0.9366 - val_loss: 0.2357 - val_accuracy: 0.9230\n",
      "Epoch 00007: early stopping\n",
      "4494/4494 [==============================] - 0s 46us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [######################        ] 100% | ETA: 00:40:39"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 297us/step - loss: 0.3783 - accuracy: 0.8738 - val_loss: 0.2983 - val_accuracy: 0.9032\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 232us/step - loss: 0.2730 - accuracy: 0.9079 - val_loss: 0.2840 - val_accuracy: 0.9023\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 221us/step - loss: 0.2379 - accuracy: 0.9226 - val_loss: 0.2426 - val_accuracy: 0.9212\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 230us/step - loss: 0.2218 - accuracy: 0.9237 - val_loss: 0.2498 - val_accuracy: 0.9143\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 229us/step - loss: 0.1994 - accuracy: 0.9320 - val_loss: 0.2298 - val_accuracy: 0.9266\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 5s 262us/step - loss: 0.1911 - accuracy: 0.9331 - val_loss: 0.2283 - val_accuracy: 0.9308\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 226us/step - loss: 0.1818 - accuracy: 0.9364 - val_loss: 0.2153 - val_accuracy: 0.9337\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 4s 227us/step - loss: 0.1696 - accuracy: 0.9419 - val_loss: 0.2232 - val_accuracy: 0.9310\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 4s 231us/step - loss: 0.1547 - accuracy: 0.9469 - val_loss: 0.2212 - val_accuracy: 0.9321\n",
      "Epoch 00009: early stopping\n",
      "4494/4494 [==============================] - 0s 72us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [#######################       ] 100% | ETA: 00:37:16"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 255us/step - loss: 0.3820 - accuracy: 0.8738 - val_loss: 0.3206 - val_accuracy: 0.8956\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 226us/step - loss: 0.2784 - accuracy: 0.9062 - val_loss: 0.2700 - val_accuracy: 0.9161\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 213us/step - loss: 0.2435 - accuracy: 0.9204 - val_loss: 0.2464 - val_accuracy: 0.9177\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 216us/step - loss: 0.2215 - accuracy: 0.9243 - val_loss: 0.2584 - val_accuracy: 0.9163\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 217us/step - loss: 0.2055 - accuracy: 0.9291 - val_loss: 0.2381 - val_accuracy: 0.9248\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 231us/step - loss: 0.1933 - accuracy: 0.9335 - val_loss: 0.2256 - val_accuracy: 0.9281\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 218us/step - loss: 0.1809 - accuracy: 0.9374 - val_loss: 0.2373 - val_accuracy: 0.9275\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 4s 229us/step - loss: 0.1699 - accuracy: 0.9428 - val_loss: 0.2307 - val_accuracy: 0.9235\n",
      "Epoch 00008: early stopping\n",
      "4494/4494 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [########################      ] 100% | ETA: 00:33:44"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 215us/step - loss: 0.3974 - accuracy: 0.8662 - val_loss: 0.2819 - val_accuracy: 0.9061\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 152us/step - loss: 0.2713 - accuracy: 0.9090 - val_loss: 0.2721 - val_accuracy: 0.9083\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 154us/step - loss: 0.2368 - accuracy: 0.9224 - val_loss: 0.2515 - val_accuracy: 0.9188\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 152us/step - loss: 0.2170 - accuracy: 0.9287 - val_loss: 0.2589 - val_accuracy: 0.9152\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 154us/step - loss: 0.1979 - accuracy: 0.9324 - val_loss: 0.2342 - val_accuracy: 0.9228\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 154us/step - loss: 0.1860 - accuracy: 0.9351 - val_loss: 0.2344 - val_accuracy: 0.9272\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 154us/step - loss: 0.1727 - accuracy: 0.9398 - val_loss: 0.2279 - val_accuracy: 0.9299\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 160us/step - loss: 0.1623 - accuracy: 0.9453 - val_loss: 0.2281 - val_accuracy: 0.9306\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 157us/step - loss: 0.1521 - accuracy: 0.9473 - val_loss: 0.2378 - val_accuracy: 0.9283\n",
      "Epoch 00009: early stopping\n",
      "4494/4494 [==============================] - 0s 46us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 204us/step - loss: 0.3842 - accuracy: 0.8721 - val_loss: 0.2936 - val_accuracy: 0.9021\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 164us/step - loss: 0.2680 - accuracy: 0.9089 - val_loss: 0.2832 - val_accuracy: 0.9083\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 173us/step - loss: 0.2325 - accuracy: 0.9250 - val_loss: 0.2408 - val_accuracy: 0.9226\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 169us/step - loss: 0.2158 - accuracy: 0.9271 - val_loss: 0.2540 - val_accuracy: 0.9194\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 166us/step - loss: 0.1972 - accuracy: 0.9325 - val_loss: 0.2325 - val_accuracy: 0.9239\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 172us/step - loss: 0.1863 - accuracy: 0.9359 - val_loss: 0.2334 - val_accuracy: 0.9259\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 168us/step - loss: 0.1712 - accuracy: 0.9434 - val_loss: 0.2299 - val_accuracy: 0.9275\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 166us/step - loss: 0.1592 - accuracy: 0.9450 - val_loss: 0.2296 - val_accuracy: 0.9281\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 155us/step - loss: 0.1523 - accuracy: 0.9460 - val_loss: 0.2355 - val_accuracy: 0.9243\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 3s 165us/step - loss: 0.1452 - accuracy: 0.9492 - val_loss: 0.2446 - val_accuracy: 0.9301\n",
      "Epoch 00010: early stopping\n",
      "4494/4494 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [#########################     ] 100% | ETA: 00:26:45"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 207us/step - loss: 0.3818 - accuracy: 0.8731 - val_loss: 0.3025 - val_accuracy: 0.8963\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 164us/step - loss: 0.2621 - accuracy: 0.9105 - val_loss: 0.2678 - val_accuracy: 0.9137\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 165us/step - loss: 0.2268 - accuracy: 0.9250 - val_loss: 0.2394 - val_accuracy: 0.9221\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 3s 168us/step - loss: 0.2081 - accuracy: 0.9305 - val_loss: 0.2467 - val_accuracy: 0.9177\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 168us/step - loss: 0.1924 - accuracy: 0.9336 - val_loss: 0.2279 - val_accuracy: 0.9290\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 169us/step - loss: 0.1822 - accuracy: 0.9369 - val_loss: 0.2434 - val_accuracy: 0.9295\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 170us/step - loss: 0.1731 - accuracy: 0.9386 - val_loss: 0.2176 - val_accuracy: 0.9312\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 172us/step - loss: 0.1576 - accuracy: 0.9465 - val_loss: 0.2277 - val_accuracy: 0.9275\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 171us/step - loss: 0.1503 - accuracy: 0.9470 - val_loss: 0.2187 - val_accuracy: 0.9328\n",
      "Epoch 00009: early stopping\n",
      "4494/4494 [==============================] - 0s 41us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [##########################    ] 100% | ETA: 00:23:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 233us/step - loss: 0.3746 - accuracy: 0.8729 - val_loss: 0.3009 - val_accuracy: 0.8990\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 184us/step - loss: 0.2693 - accuracy: 0.9094 - val_loss: 0.2722 - val_accuracy: 0.9126\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 181us/step - loss: 0.2329 - accuracy: 0.9232 - val_loss: 0.2330 - val_accuracy: 0.9228\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 196us/step - loss: 0.2124 - accuracy: 0.9278 - val_loss: 0.2528 - val_accuracy: 0.9168\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 199us/step - loss: 0.1967 - accuracy: 0.9329 - val_loss: 0.2305 - val_accuracy: 0.9255\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 189us/step - loss: 0.1828 - accuracy: 0.9372 - val_loss: 0.2252 - val_accuracy: 0.9283\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 186us/step - loss: 0.1727 - accuracy: 0.9406 - val_loss: 0.2045 - val_accuracy: 0.9341\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 186us/step - loss: 0.1608 - accuracy: 0.9432 - val_loss: 0.2229 - val_accuracy: 0.9308\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 183us/step - loss: 0.1503 - accuracy: 0.9467 - val_loss: 0.2096 - val_accuracy: 0.9319\n",
      "Epoch 00009: early stopping\n",
      "4494/4494 [==============================] - 0s 42us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 268us/step - loss: 0.3804 - accuracy: 0.8716 - val_loss: 0.3051 - val_accuracy: 0.8954\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 210us/step - loss: 0.2656 - accuracy: 0.9109 - val_loss: 0.2797 - val_accuracy: 0.9112\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 223us/step - loss: 0.2291 - accuracy: 0.9256 - val_loss: 0.2429 - val_accuracy: 0.9168\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 231us/step - loss: 0.2140 - accuracy: 0.9285 - val_loss: 0.2734 - val_accuracy: 0.9083\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 5s 252us/step - loss: 0.1974 - accuracy: 0.9342 - val_loss: 0.2208 - val_accuracy: 0.9275\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 5s 259us/step - loss: 0.1806 - accuracy: 0.9375 - val_loss: 0.2367 - val_accuracy: 0.9272\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 5s 253us/step - loss: 0.1736 - accuracy: 0.9401 - val_loss: 0.2151 - val_accuracy: 0.9344\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 4s 213us/step - loss: 0.1592 - accuracy: 0.9452 - val_loss: 0.2292 - val_accuracy: 0.9324\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 4s 236us/step - loss: 0.1471 - accuracy: 0.9474 - val_loss: 0.2254 - val_accuracy: 0.9299\n",
      "Epoch 00009: early stopping\n",
      "4494/4494 [==============================] - 0s 56us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [###########################   ] 100% | ETA: 00:15:37"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 231us/step - loss: 0.3802 - accuracy: 0.8713 - val_loss: 0.2981 - val_accuracy: 0.8981\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 206us/step - loss: 0.2694 - accuracy: 0.9086 - val_loss: 0.2704 - val_accuracy: 0.9119\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 3s 194us/step - loss: 0.2340 - accuracy: 0.9233 - val_loss: 0.2308 - val_accuracy: 0.9237\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 197us/step - loss: 0.2177 - accuracy: 0.9278 - val_loss: 0.2731 - val_accuracy: 0.9072\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 195us/step - loss: 0.1995 - accuracy: 0.9315 - val_loss: 0.2217 - val_accuracy: 0.9275\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 194us/step - loss: 0.1875 - accuracy: 0.9353 - val_loss: 0.2377 - val_accuracy: 0.9219\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 207us/step - loss: 0.1755 - accuracy: 0.9394 - val_loss: 0.2251 - val_accuracy: 0.9281\n",
      "Epoch 00007: early stopping\n",
      "4494/4494 [==============================] - 0s 44us/step\n",
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 7s 385us/step - loss: 0.3740 - accuracy: 0.8733 - val_loss: 0.3174 - val_accuracy: 0.8936\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 246us/step - loss: 0.2700 - accuracy: 0.9095 - val_loss: 0.2651 - val_accuracy: 0.9121\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 250us/step - loss: 0.2328 - accuracy: 0.9226 - val_loss: 0.2332 - val_accuracy: 0.9237\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 5s 259us/step - loss: 0.2159 - accuracy: 0.9272 - val_loss: 0.2626 - val_accuracy: 0.9163\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 5s 252us/step - loss: 0.1979 - accuracy: 0.9342 - val_loss: 0.2206 - val_accuracy: 0.9317\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 205us/step - loss: 0.1853 - accuracy: 0.9363 - val_loss: 0.2295 - val_accuracy: 0.9290\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 204us/step - loss: 0.1763 - accuracy: 0.9398 - val_loss: 0.2351 - val_accuracy: 0.9255\n",
      "Epoch 00007: early stopping\n",
      "4494/4494 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [############################  ] 100% | ETA: 00:07:56"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 256us/step - loss: 0.3795 - accuracy: 0.8747 - val_loss: 0.2922 - val_accuracy: 0.9070\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 5s 253us/step - loss: 0.2654 - accuracy: 0.9109 - val_loss: 0.2774 - val_accuracy: 0.9072\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 236us/step - loss: 0.2330 - accuracy: 0.9234 - val_loss: 0.2442 - val_accuracy: 0.9188\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 5s 256us/step - loss: 0.2139 - accuracy: 0.9277 - val_loss: 0.2752 - val_accuracy: 0.9077\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 241us/step - loss: 0.1962 - accuracy: 0.9332 - val_loss: 0.2184 - val_accuracy: 0.9279\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 5s 256us/step - loss: 0.1833 - accuracy: 0.9367 - val_loss: 0.2445 - val_accuracy: 0.9206\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 237us/step - loss: 0.1775 - accuracy: 0.9373 - val_loss: 0.2340 - val_accuracy: 0.9299\n",
      "Epoch 00007: early stopping\n",
      "4494/4494 [==============================] - 0s 56us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [############################# ] 100% | ETA: 00:03:59"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 257us/step - loss: 0.3733 - accuracy: 0.8746 - val_loss: 0.3097 - val_accuracy: 0.8968\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 205us/step - loss: 0.2699 - accuracy: 0.9088 - val_loss: 0.2672 - val_accuracy: 0.9128\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 211us/step - loss: 0.2384 - accuracy: 0.9206 - val_loss: 0.2337 - val_accuracy: 0.9223\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 218us/step - loss: 0.2179 - accuracy: 0.9255 - val_loss: 0.2640 - val_accuracy: 0.9121\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 215us/step - loss: 0.2010 - accuracy: 0.9305 - val_loss: 0.2308 - val_accuracy: 0.9268\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 218us/step - loss: 0.1863 - accuracy: 0.9366 - val_loss: 0.2363 - val_accuracy: 0.9226\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 220us/step - loss: 0.1771 - accuracy: 0.9376 - val_loss: 0.2325 - val_accuracy: 0.9279\n",
      "Epoch 00007: early stopping\n",
      "4494/4494 [==============================] - 0s 44us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 03:00:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: \n",
      "  Started: 06/24/2020 12:48:55\n",
      "  Finished: 06/24/2020 15:49:34\n",
      "  Total time elapsed: 03:00:38\n",
      "  CPU %: 234.90\n",
      "  Memory %: 6.31\n"
     ]
    }
   ],
   "source": [
    "param_dict = {'walk_length': [40, 50, 60, 70, 80],\n",
    "              'embedding_dimensions': [80, 90, 100, 110, 120, 130, 140, 150, 160]}\n",
    "\n",
    "results = grid_search('neural network', param_dict, graph, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>walk_length</th>\n",
       "      <th>embedding_dimensions</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "      <td>0.916110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>90</td>\n",
       "      <td>0.919003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>0.922786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>110</td>\n",
       "      <td>0.922118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>120</td>\n",
       "      <td>0.923899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>130</td>\n",
       "      <td>0.921673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>0.920116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>0.921451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40</td>\n",
       "      <td>160</td>\n",
       "      <td>0.921451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "      <td>0.919003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>0.923454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.927236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>110</td>\n",
       "      <td>0.927904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>120</td>\n",
       "      <td>0.928349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>130</td>\n",
       "      <td>0.923008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50</td>\n",
       "      <td>140</td>\n",
       "      <td>0.927236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>0.931687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>0.925679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>0.922563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>0.928794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.923899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>0.918558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>60</td>\n",
       "      <td>120</td>\n",
       "      <td>0.924121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>60</td>\n",
       "      <td>130</td>\n",
       "      <td>0.926346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>60</td>\n",
       "      <td>140</td>\n",
       "      <td>0.927904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>0.923231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>60</td>\n",
       "      <td>160</td>\n",
       "      <td>0.922786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>0.926791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>0.927904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "      <td>0.923008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>70</td>\n",
       "      <td>110</td>\n",
       "      <td>0.929907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>0.925901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>70</td>\n",
       "      <td>130</td>\n",
       "      <td>0.927681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>70</td>\n",
       "      <td>140</td>\n",
       "      <td>0.923008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>70</td>\n",
       "      <td>150</td>\n",
       "      <td>0.932132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>70</td>\n",
       "      <td>160</td>\n",
       "      <td>0.923454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>0.928349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>0.930129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>0.932799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>0.931909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>0.929907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>80</td>\n",
       "      <td>130</td>\n",
       "      <td>0.928126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>80</td>\n",
       "      <td>140</td>\n",
       "      <td>0.925456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>80</td>\n",
       "      <td>150</td>\n",
       "      <td>0.929907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>0.927904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    walk_length  embedding_dimensions  accuracy\n",
       "0            40                    80  0.916110\n",
       "1            40                    90  0.919003\n",
       "2            40                   100  0.922786\n",
       "3            40                   110  0.922118\n",
       "4            40                   120  0.923899\n",
       "5            40                   130  0.921673\n",
       "6            40                   140  0.920116\n",
       "7            40                   150  0.921451\n",
       "8            40                   160  0.921451\n",
       "9            50                    80  0.919003\n",
       "10           50                    90  0.923454\n",
       "11           50                   100  0.927236\n",
       "12           50                   110  0.927904\n",
       "13           50                   120  0.928349\n",
       "14           50                   130  0.923008\n",
       "15           50                   140  0.927236\n",
       "16           50                   150  0.931687\n",
       "17           50                   160  0.925679\n",
       "18           60                    80  0.922563\n",
       "19           60                    90  0.928794\n",
       "20           60                   100  0.923899\n",
       "21           60                   110  0.918558\n",
       "22           60                   120  0.924121\n",
       "23           60                   130  0.926346\n",
       "24           60                   140  0.927904\n",
       "25           60                   150  0.923231\n",
       "26           60                   160  0.922786\n",
       "27           70                    80  0.926791\n",
       "28           70                    90  0.927904\n",
       "29           70                   100  0.923008\n",
       "30           70                   110  0.929907\n",
       "31           70                   120  0.925901\n",
       "32           70                   130  0.927681\n",
       "33           70                   140  0.923008\n",
       "34           70                   150  0.932132\n",
       "35           70                   160  0.923454\n",
       "36           80                    80  0.928349\n",
       "37           80                    90  0.930129\n",
       "38           80                   100  0.932799\n",
       "39           80                   110  0.931909\n",
       "40           80                   120  0.929907\n",
       "41           80                   130  0.928126\n",
       "42           80                   140  0.925456\n",
       "43           80                   150  0.929907\n",
       "44           80                   160  0.927904"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuracy_embedding_dims = results.groupby('embedding_dimensions').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuracy_walk_length = results.groupby('walk_length').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffc296ac6d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Embedding Dimensions and Average Accuracy')\n",
    "sns.lineplot(avg_accuracy_embedding_dims.index, 100*avg_accuracy_embedding_dims['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffbaf054cd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Walk Length and Average Accuracy')\n",
    "sns.lineplot(avg_accuracy_walk_length.index, 100*avg_accuracy_walk_length['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
