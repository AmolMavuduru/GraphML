{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from karateclub import GraphReader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = GraphReader(\"facebook\")\n",
    "\n",
    "graph = reader.get_graph()\n",
    "target = reader.get_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22470"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepWalk Graph Embedding and ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from karateclub import DeepWalk\n",
    "deepwalk = DeepWalk(walk_length=100, dimensions=256)\n",
    "deepwalk.fit(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = deepwalk.get_embedding()\n",
    "y = target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.76      1340\n",
      "           1       0.64      0.51      0.57       671\n",
      "           2       0.70      0.71      0.70      1125\n",
      "           3       0.75      0.79      0.77      1358\n",
      "\n",
      "    accuracy                           0.72      4494\n",
      "   macro avg       0.71      0.70      0.70      4494\n",
      "weighted avg       0.72      0.72      0.72      4494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.4f}'.format(acc))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.78      0.68      1340\n",
      "           1       0.83      0.10      0.17       671\n",
      "           2       0.66      0.56      0.60      1125\n",
      "           3       0.64      0.81      0.71      1358\n",
      "\n",
      "    accuracy                           0.63      4494\n",
      "   macro avg       0.68      0.56      0.54      4494\n",
      "weighted avg       0.66      0.63      0.59      4494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.4f}'.format(acc))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 100, 100), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "neural_net = MLPClassifier(hidden_layer_sizes=(100, 100, 100))\n",
    "neural_net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      1340\n",
      "           1       0.69      0.69      0.69       671\n",
      "           2       0.81      0.80      0.81      1125\n",
      "           3       0.83      0.84      0.84      1358\n",
      "\n",
      "    accuracy                           0.80      4494\n",
      "   macro avg       0.78      0.78      0.78      4494\n",
      "weighted avg       0.80      0.80      0.80      4494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = neural_net.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.4f}'.format(acc))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper Neural Network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    verbose=2,\n",
    "    mode=\"min\")\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    verbose=2,\n",
    "    mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 4s 220us/step - loss: 1.1638 - accuracy: 0.4724 - val_loss: 1.0708 - val_accuracy: 0.5467\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 3s 186us/step - loss: 0.9692 - accuracy: 0.6637 - val_loss: 0.8809 - val_accuracy: 0.7107\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 210us/step - loss: 0.7884 - accuracy: 0.7521 - val_loss: 0.7643 - val_accuracy: 0.7546\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 196us/step - loss: 0.6678 - accuracy: 0.7936 - val_loss: 0.7082 - val_accuracy: 0.7659\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 3s 180us/step - loss: 0.5695 - accuracy: 0.8268 - val_loss: 0.6518 - val_accuracy: 0.7828\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 3s 181us/step - loss: 0.4963 - accuracy: 0.8480 - val_loss: 0.6097 - val_accuracy: 0.7973\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 3s 181us/step - loss: 0.4311 - accuracy: 0.8712 - val_loss: 0.5980 - val_accuracy: 0.8042\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 3s 179us/step - loss: 0.3792 - accuracy: 0.8907 - val_loss: 0.6057 - val_accuracy: 0.8040\n",
      "Epoch 9/10\n",
      "17976/17976 [==============================] - 3s 180us/step - loss: 0.3509 - accuracy: 0.8966 - val_loss: 0.5847 - val_accuracy: 0.8082\n",
      "Epoch 10/10\n",
      "17976/17976 [==============================] - 3s 183us/step - loss: 0.3070 - accuracy: 0.9128 - val_loss: 0.6208 - val_accuracy: 0.8055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe1946bb850>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "\n",
    "model.fit(X_train, y_train_cat, \n",
    "          validation_data=(X_test, y_test_cat),\n",
    "          batch_size=32, epochs=10,\n",
    "         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4494/4494 [==============================] - 0s 52us/step\n",
      "Accuracy: 0.8055\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(X_test, y_test_cat)\n",
    "print('Accuracy: {:.4f}'.format(evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walklets Embedding and ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from karateclub import Walklets\n",
    "walklet_embedder = Walklets(dimensions=128)\n",
    "walklet_embedder.fit(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = walklet_embedder.get_embedding()\n",
    "y = target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amol/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      1340\n",
      "           1       0.88      0.85      0.87       671\n",
      "           2       0.92      0.93      0.93      1125\n",
      "           3       0.92      0.92      0.92      1358\n",
      "\n",
      "    accuracy                           0.91      4494\n",
      "   macro avg       0.91      0.91      0.91      4494\n",
      "weighted avg       0.91      0.91      0.91      4494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.4f}'.format(acc))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 100, 100), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "neural_net = MLPClassifier(hidden_layer_sizes=(100, 100, 100))\n",
    "neural_net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9357\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      1340\n",
      "           1       0.92      0.90      0.91       671\n",
      "           2       0.95      0.94      0.95      1125\n",
      "           3       0.93      0.94      0.94      1358\n",
      "\n",
      "    accuracy                           0.94      4494\n",
      "   macro avg       0.93      0.93      0.93      4494\n",
      "weighted avg       0.94      0.94      0.94      4494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = neural_net.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.4f}'.format(acc))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    verbose=2,\n",
    "    mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17976 samples, validate on 4494 samples\n",
      "Epoch 1/10\n",
      "17976/17976 [==============================] - 5s 264us/step - loss: 0.3720 - accuracy: 0.8738 - val_loss: 0.2852 - val_accuracy: 0.9079\n",
      "Epoch 2/10\n",
      "17976/17976 [==============================] - 4s 219us/step - loss: 0.2694 - accuracy: 0.9104 - val_loss: 0.2631 - val_accuracy: 0.9123\n",
      "Epoch 3/10\n",
      "17976/17976 [==============================] - 4s 202us/step - loss: 0.2342 - accuracy: 0.9219 - val_loss: 0.2340 - val_accuracy: 0.9275\n",
      "Epoch 4/10\n",
      "17976/17976 [==============================] - 4s 206us/step - loss: 0.2136 - accuracy: 0.9282 - val_loss: 0.2350 - val_accuracy: 0.9292\n",
      "Epoch 5/10\n",
      "17976/17976 [==============================] - 4s 198us/step - loss: 0.2000 - accuracy: 0.9326 - val_loss: 0.2217 - val_accuracy: 0.9306\n",
      "Epoch 6/10\n",
      "17976/17976 [==============================] - 4s 199us/step - loss: 0.1855 - accuracy: 0.9351 - val_loss: 0.2214 - val_accuracy: 0.9328\n",
      "Epoch 7/10\n",
      "17976/17976 [==============================] - 4s 200us/step - loss: 0.1701 - accuracy: 0.9414 - val_loss: 0.2292 - val_accuracy: 0.9286\n",
      "Epoch 8/10\n",
      "17976/17976 [==============================] - 4s 202us/step - loss: 0.1609 - accuracy: 0.9438 - val_loss: 0.2473 - val_accuracy: 0.9250\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe143f69610>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "\n",
    "model.fit(X_train, y_train_cat, \n",
    "          validation_data=(X_test, y_test_cat),\n",
    "          batch_size=32, epochs=10,\n",
    "         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4494/4494 [==============================] - 0s 49us/step\n",
      "Accuracy: 0.9250\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(X_test, y_test_cat)\n",
    "print('Accuracy: {:.4f}'.format(evaluation[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
